{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cd9f166",
   "metadata": {},
   "source": [
    "# Prompting Tutorial\n",
    "## This is a tutorial for prompting. We will use a few shot sentiment analysis task to show how to do prompting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a674f3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM,AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4366cc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3e006bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45b007bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "906a9399b1f14fd18fcbcee2305b097e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)enizer_config.json\";:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:129: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\qishe\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd335efa000e4be4a96e55bb35004d53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"config.json\";:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "020f446db8114553aa5a1e833dd1e0c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"vocab.txt\";:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38fa176da025492f84e3ac5265088f9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"tokenizer.json\";:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "457a389d31f442c3b8964c772afb98b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb95a495",
   "metadata": {},
   "source": [
    "### An Example of Zero-shot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22b7fd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "Text='The review is [MASK]. Review: It is a good movie.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d43f028",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tokenizer(Text, truncation=True, padding=True,return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a602434b",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(encoding['input_ids'], attention_mask=encoding['attention_mask'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee2ae71",
   "metadata": {},
   "source": [
    "The mask token 103 is the fifth token "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ebf18b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 1996, 3319, 2003,  103, 1012, 3319, 1024, 2009, 2003, 1037, 2204,\n",
       "         3185, 1012,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03989a4d",
   "metadata": {},
   "source": [
    "so we use logits[0,4,:] to get the logit of the mask token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c07a556",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits=outputs.logits[0,4,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36447e53",
   "metadata": {},
   "source": [
    "Check the first five result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e572c699",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5_tokens = np.argsort(-logits.detach().numpy())[:5].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45787d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> The review is positive. Review: It is a good movie.\n",
      ">>> The review is mixed. Review: It is a good movie.\n",
      ">>> The review is excellent. Review: It is a good movie.\n",
      ">>> The review is good. Review: It is a good movie.\n",
      ">>> The review is negative. Review: It is a good movie.\n"
     ]
    }
   ],
   "source": [
    "for token in top_5_tokens:\n",
    "    print(f\">>> {Text.replace(tokenizer.mask_token, tokenizer.decode([token]))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37e07d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "309f9281",
   "metadata": {},
   "source": [
    "### In this tutorial, we choose the IMDB Dataset as our dataset. It has 50000 movie reviews, 25000 for postive and 25000 for negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bb84513",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('IMDB Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13d31500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c214821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Prompt\n",
    "review_lst=data['review'].to_list()\n",
    "#For each sample we will add the prompt and add it to the prompt list\n",
    "prompt=[]\n",
    "for sentence in review_lst:\n",
    "    new_string='The review is [MASK]. Review: '+sentence\n",
    "    prompt.append(new_string)\n",
    "#create new colunmn in data as prompt\n",
    "data['prompt']=prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0215f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>The review is [MASK]. Review: One of the other...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>The review is [MASK]. Review: A wonderful litt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>The review is [MASK]. Review: I thought this w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>The review is [MASK]. Review: Basically there'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>The review is [MASK]. Review: Petter Mattei's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "      <td>The review is [MASK]. Review: I thought this m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "      <td>The review is [MASK]. Review: Bad plot, bad di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "      <td>The review is [MASK]. Review: I am a Catholic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "      <td>The review is [MASK]. Review: I'm going to hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "      <td>The review is [MASK]. Review: No one expects t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment  \\\n",
       "0      One of the other reviewers has mentioned that ...  positive   \n",
       "1      A wonderful little production. <br /><br />The...  positive   \n",
       "2      I thought this was a wonderful way to spend ti...  positive   \n",
       "3      Basically there's a family where a little boy ...  negative   \n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive   \n",
       "...                                                  ...       ...   \n",
       "49995  I thought this movie did a down right good job...  positive   \n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative   \n",
       "49997  I am a Catholic taught in parochial elementary...  negative   \n",
       "49998  I'm going to have to disagree with the previou...  negative   \n",
       "49999  No one expects the Star Trek movies to be high...  negative   \n",
       "\n",
       "                                                  prompt  \n",
       "0      The review is [MASK]. Review: One of the other...  \n",
       "1      The review is [MASK]. Review: A wonderful litt...  \n",
       "2      The review is [MASK]. Review: I thought this w...  \n",
       "3      The review is [MASK]. Review: Basically there'...  \n",
       "4      The review is [MASK]. Review: Petter Mattei's ...  \n",
       "...                                                  ...  \n",
       "49995  The review is [MASK]. Review: I thought this m...  \n",
       "49996  The review is [MASK]. Review: Bad plot, bad di...  \n",
       "49997  The review is [MASK]. Review: I am a Catholic ...  \n",
       "49998  The review is [MASK]. Review: I'm going to hav...  \n",
       "49999  The review is [MASK]. Review: No one expects t...  \n",
       "\n",
       "[50000 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76602193",
   "metadata": {},
   "source": [
    "check the encoding of positive and negative in tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c597f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([3893])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "437ff3d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([4997])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e46d38",
   "metadata": {},
   "source": [
    "Add targets. We want to predict the mask token to be postive or negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14ee409c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['target'] = data['sentiment'].replace(['positive','negative'], [3893,4997])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7e665b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>prompt</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>The review is [MASK]. Review: One of the other...</td>\n",
       "      <td>3893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>The review is [MASK]. Review: A wonderful litt...</td>\n",
       "      <td>3893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>The review is [MASK]. Review: I thought this w...</td>\n",
       "      <td>3893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>The review is [MASK]. Review: Basically there'...</td>\n",
       "      <td>4997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>The review is [MASK]. Review: Petter Mattei's ...</td>\n",
       "      <td>3893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "      <td>The review is [MASK]. Review: I thought this m...</td>\n",
       "      <td>3893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "      <td>The review is [MASK]. Review: Bad plot, bad di...</td>\n",
       "      <td>4997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "      <td>The review is [MASK]. Review: I am a Catholic ...</td>\n",
       "      <td>4997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "      <td>The review is [MASK]. Review: I'm going to hav...</td>\n",
       "      <td>4997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "      <td>The review is [MASK]. Review: No one expects t...</td>\n",
       "      <td>4997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment  \\\n",
       "0      One of the other reviewers has mentioned that ...  positive   \n",
       "1      A wonderful little production. <br /><br />The...  positive   \n",
       "2      I thought this was a wonderful way to spend ti...  positive   \n",
       "3      Basically there's a family where a little boy ...  negative   \n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive   \n",
       "...                                                  ...       ...   \n",
       "49995  I thought this movie did a down right good job...  positive   \n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative   \n",
       "49997  I am a Catholic taught in parochial elementary...  negative   \n",
       "49998  I'm going to have to disagree with the previou...  negative   \n",
       "49999  No one expects the Star Trek movies to be high...  negative   \n",
       "\n",
       "                                                  prompt  target  \n",
       "0      The review is [MASK]. Review: One of the other...    3893  \n",
       "1      The review is [MASK]. Review: A wonderful litt...    3893  \n",
       "2      The review is [MASK]. Review: I thought this w...    3893  \n",
       "3      The review is [MASK]. Review: Basically there'...    4997  \n",
       "4      The review is [MASK]. Review: Petter Mattei's ...    3893  \n",
       "...                                                  ...     ...  \n",
       "49995  The review is [MASK]. Review: I thought this m...    3893  \n",
       "49996  The review is [MASK]. Review: Bad plot, bad di...    4997  \n",
       "49997  The review is [MASK]. Review: I am a Catholic ...    4997  \n",
       "49998  The review is [MASK]. Review: I'm going to hav...    4997  \n",
       "49999  The review is [MASK]. Review: No one expects t...    4997  \n",
       "\n",
       "[50000 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8acb8df",
   "metadata": {},
   "source": [
    "### Create a subset with 2 samples one for positive and one for negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ca3162b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_shot=data.groupby('sentiment').tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7581129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>prompt</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "      <td>The review is [MASK]. Review: I thought this m...</td>\n",
       "      <td>3893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "      <td>The review is [MASK]. Review: No one expects t...</td>\n",
       "      <td>4997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment  \\\n",
       "49995  I thought this movie did a down right good job...  positive   \n",
       "49999  No one expects the Star Trek movies to be high...  negative   \n",
       "\n",
       "                                                  prompt  target  \n",
       "49995  The review is [MASK]. Review: I thought this m...    3893  \n",
       "49999  The review is [MASK]. Review: No one expects t...    4997  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_shot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52855a41",
   "metadata": {},
   "source": [
    "### Create a subset with 32 samples 16 for positive and 16 for negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4ac2eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot=data.groupby('sentiment').head(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640671eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "103506b4",
   "metadata": {},
   "source": [
    "Customized Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19faf101",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset():\n",
    "\n",
    "    def __init__(self, dataframe, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.prompts = list(dataframe['prompt'])\n",
    "        self.targets = list(dataframe['target'])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.prompts)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "    \n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            self.prompts[index],\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=512,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        ids_content = inputs['input_ids']\n",
    "        mask_content = inputs['attention_mask']\n",
    "        token_type_ids_content = inputs[\"token_type_ids\"]\n",
    "        targets=self.targets[index]\n",
    "        return torch.tensor(ids_content, dtype=torch.long),torch.tensor(mask_content, dtype=torch.long),torch.tensor(token_type_ids_content, dtype=torch.long),torch.tensor(targets, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71037bf1",
   "metadata": {},
   "source": [
    "dataloders for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "257c2eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_shot_set = CustomDataset(one_shot, tokenizer)\n",
    "\n",
    "oneshotloader = DataLoader(one_shot_set, batch_size=2,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a06e68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_set = CustomDataset(few_shot, tokenizer)\n",
    "\n",
    "fewshotloader = DataLoader(few_shot_set, batch_size=2,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f8fb11d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = CustomDataset(data[:5000], tokenizer)\n",
    "\n",
    "testloader = DataLoader(test_set, batch_size=2,shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97cd241",
   "metadata": {},
   "source": [
    "# Training and Evaluating functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e75f4c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(train_loader, model, criterion,optimizer):\n",
    "    \"\"\"one epoch training\"\"\"\n",
    "\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    epoch_acc = 0\n",
    "   \n",
    "    model.train()\n",
    "\n",
    "\n",
    "    for idx, (input_ids,attention_mask,token_type_ids,targets) in enumerate(train_loader):\n",
    "\n",
    "\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            input_ids = input_ids.cuda()\n",
    "            attention_mask = attention_mask.cuda()\n",
    "            targets= targets.cuda()\n",
    "\n",
    "\n",
    "        # compute logits\n",
    "        outputs = model(input_ids, attention_mask=attention_mask).logits\n",
    "        #the mask token logits is in outputs[:,4,:]\n",
    "        pred=outputs[:,4,:]\n",
    "        \n",
    "        #calculate the loss and accuracy\n",
    "        loss = criterion(pred, targets)\n",
    "        acc = calculate_accuracy(pred, targets)\n",
    "        \n",
    "        #accumulate the loss and accuracy\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "\n",
    "        # SGD\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    return epoch_loss / len(train_loader), epoch_acc / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0499b253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(eval_loader, model,  criterion):\n",
    "    epoch_loss = 0\n",
    "\n",
    "    epoch_acc = 0\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for idx, (input_ids,attention_mask,token_type_ids,targets) in enumerate(eval_loader):\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                input_ids = input_ids.cuda()\n",
    "                attention_mask = attention_mask.cuda()\n",
    "                targets= targets.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # compute logits\n",
    "            outputs = model(input_ids, attention_mask=attention_mask).logits\n",
    "            #the mask token logits is in outputs[:,4,:]\n",
    "            pred=outputs[:,4,:]\n",
    "            \n",
    "            #calculate the loss and accuracy\n",
    "            loss = criterion(pred, targets)\n",
    "            acc = calculate_accuracy(pred, targets)\n",
    "            \n",
    "            #accumulate the loss and accuracy\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(eval_loader), epoch_acc / len(eval_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "061182be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate accuracy\n",
    "def calculate_accuracy(y_pred, y):\n",
    "    top_pred = y_pred.argmax(1, keepdim = True)\n",
    "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
    "    acc = correct.float() / y.shape[0]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8899def5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=1e-6,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8cb7de05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/300 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs:1\n",
      "training_loss:2.6284995079040527, acc:0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|▎                                                                               | 1/300 [01:38<8:12:50, 98.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_loss:1.8543546616435052, ts_acc:0.469\n",
      "epochs:2\n",
      "training_loss:2.494699239730835, acc:0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                             | 1/300 [02:42<13:31:40, 162.88s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [39]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining_loss:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtr_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, acc:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtr_acc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m#evaluating\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m ts_loss,ts_acc\u001b[38;5;241m=\u001b[39m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtestloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mts_loss:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mts_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, ts_acc:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mts_acc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[1;32mIn [26]\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(eval_loader, model, criterion)\u001b[0m\n\u001b[0;32m     25\u001b[0m         acc \u001b[38;5;241m=\u001b[39m calculate_accuracy(pred, targets)\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;66;03m#accumulate the loss and accuracy\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m         epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m         epoch_acc \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m acc\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m epoch_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(eval_loader), epoch_acc \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(eval_loader)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#training and evaluate\n",
    "for i in tqdm.tqdm(range(300)):\n",
    "\n",
    "\n",
    "    print(f\"epochs:{i+1}\")\n",
    "    \n",
    "    #training\n",
    "    tr_loss,tr_acc=training(oneshotloader, model, criterion,optimizer)\n",
    "    print(f'training_loss:{tr_loss}, acc:{tr_acc}')\n",
    "\n",
    "    #evaluating\n",
    "    ts_loss,ts_acc=evaluate(testloader, model,  criterion)\n",
    "    print(f'ts_loss:{ts_loss}, ts_acc:{ts_acc}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9baaba",
   "metadata": {},
   "source": [
    "### After 35 epochs, the accracy reachs 0.78 for testing with only 2 samples in training\n",
    "### After 30 epochs, the accracy reachs 0.82 for testing with only 36 samples in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "de366902",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(MyModel, self).__init__()\n",
    "        \n",
    "        self.model_bert = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
    "        self.model_bert.dropout = nn.Identity()\n",
    "        self.model_bert.classifier = nn.Identity()\n",
    "        \n",
    "        self.head = nn.Sequential(\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(768, num_classes)\n",
    "        )\n",
    "       \n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.model_bert(x).logits\n",
    "        classes = self.head(x)\n",
    "        \n",
    "        return classes\n",
    "\n",
    "\n",
    "\n",
    "model = MyModel(2)\n",
    "\n",
    "#for param in model.model_roberta.parameters():\n",
    "#    param.requires_grad = False\n",
    "\n",
    "# In[33]:\n",
    "\n",
    "\n",
    "def training(train_loader, model,criterion, optimizer):\n",
    "\n",
    "\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_loss1 = 0\n",
    "    epoch_loss2 = 0\n",
    "    epoch_acc = 0\n",
    "   \n",
    "    model.train()\n",
    "\n",
    "\n",
    "    for idx, (text,label) in enumerate(train_loader):\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        text=text.to(device)\n",
    "        label=label.to(device)\n",
    "        classes = model(text)\n",
    "        loss=criterion(classes,label)\n",
    "\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "             \n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        acc = calculate_accuracy(classes, label)\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return epoch_loss / len(train_loader), epoch_acc / len(train_loader)\n",
    "def evaluate(train_loader, model,criterion, optimizer):\n",
    "\n",
    "\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_loss1 = 0\n",
    "    epoch_loss2 = 0\n",
    "    epoch_acc = 0\n",
    "   \n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (text,label) in enumerate(train_loader):\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "            text=text.to(device)\n",
    "            label=label.to(device)\n",
    "\n",
    "            classes = model(text)\n",
    "            loss=criterion(classes,label)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        \n",
    "             \n",
    "\n",
    "        \n",
    "\n",
    "            acc = calculate_accuracy(classes, label)\n",
    "        \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    return epoch_loss / len(train_loader), epoch_acc / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bc10036f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['target_2'] = data['target'].replace([3893,4997], [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1d75ba82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>prompt</th>\n",
       "      <th>target</th>\n",
       "      <th>target_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>The review is [MASK]. Review: One of the other...</td>\n",
       "      <td>3893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>The review is [MASK]. Review: A wonderful litt...</td>\n",
       "      <td>3893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>The review is [MASK]. Review: I thought this w...</td>\n",
       "      <td>3893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>The review is [MASK]. Review: Basically there'...</td>\n",
       "      <td>4997</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>The review is [MASK]. Review: Petter Mattei's ...</td>\n",
       "      <td>3893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "      <td>The review is [MASK]. Review: I thought this m...</td>\n",
       "      <td>3893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "      <td>The review is [MASK]. Review: Bad plot, bad di...</td>\n",
       "      <td>4997</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "      <td>The review is [MASK]. Review: I am a Catholic ...</td>\n",
       "      <td>4997</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "      <td>The review is [MASK]. Review: I'm going to hav...</td>\n",
       "      <td>4997</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "      <td>The review is [MASK]. Review: No one expects t...</td>\n",
       "      <td>4997</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment  \\\n",
       "0      One of the other reviewers has mentioned that ...  positive   \n",
       "1      A wonderful little production. <br /><br />The...  positive   \n",
       "2      I thought this was a wonderful way to spend ti...  positive   \n",
       "3      Basically there's a family where a little boy ...  negative   \n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive   \n",
       "...                                                  ...       ...   \n",
       "49995  I thought this movie did a down right good job...  positive   \n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative   \n",
       "49997  I am a Catholic taught in parochial elementary...  negative   \n",
       "49998  I'm going to have to disagree with the previou...  negative   \n",
       "49999  No one expects the Star Trek movies to be high...  negative   \n",
       "\n",
       "                                                  prompt  target  target_2  \n",
       "0      The review is [MASK]. Review: One of the other...    3893         0  \n",
       "1      The review is [MASK]. Review: A wonderful litt...    3893         0  \n",
       "2      The review is [MASK]. Review: I thought this w...    3893         0  \n",
       "3      The review is [MASK]. Review: Basically there'...    4997         1  \n",
       "4      The review is [MASK]. Review: Petter Mattei's ...    3893         0  \n",
       "...                                                  ...     ...       ...  \n",
       "49995  The review is [MASK]. Review: I thought this m...    3893         0  \n",
       "49996  The review is [MASK]. Review: Bad plot, bad di...    4997         1  \n",
       "49997  The review is [MASK]. Review: I am a Catholic ...    4997         1  \n",
       "49998  The review is [MASK]. Review: I'm going to hav...    4997         1  \n",
       "49999  The review is [MASK]. Review: No one expects t...    4997         1  \n",
       "\n",
       "[50000 rows x 5 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "74dc33ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_shot_set = CustomDataset(one_shot, tokenizer)\n",
    "\n",
    "oneshotloader = DataLoader(one_shot_set, batch_size=2,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f4f0b252",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_set = CustomDataset(few_shot, tokenizer)\n",
    "\n",
    "fewshotloader = DataLoader(few_shot_set, batch_size=2,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9a045259",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = CustomDataset(data[:5000], tokenizer)\n",
    "\n",
    "testloader = DataLoader(test_set, batch_size=2,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9e51a4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/300 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs:1\n",
      "training_loss:0.7085570096969604, acc:0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|▎                                                                               | 1/300 [01:07<5:37:48, 67.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_loss:0.7051917013049126, ts_acc:0.508\n",
      "epochs:2\n",
      "training_loss:0.6451234221458435, acc:1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▌                                                                               | 2/300 [02:11<5:24:06, 65.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_loss:0.7070887587189675, ts_acc:0.5068\n",
      "epochs:3\n",
      "training_loss:0.635071873664856, acc:0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▊                                                                               | 3/300 [03:14<5:18:27, 64.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_loss:0.708279135298729, ts_acc:0.5066\n",
      "epochs:4\n",
      "training_loss:0.5916577577590942, acc:1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▊                                                                               | 3/300 [03:20<5:31:12, 66.91s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [69]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining_loss:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtr_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, acc:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtr_acc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#evaluating\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m ts_loss,ts_acc\u001b[38;5;241m=\u001b[39m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtestloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mts_loss:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mts_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, ts_acc:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mts_acc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[1;32mIn [66]\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(train_loader, model, criterion, optimizer)\u001b[0m\n\u001b[0;32m     98\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m    105\u001b[0m         acc \u001b[38;5;241m=\u001b[39m calculate_accuracy(classes, label)\n\u001b[1;32m--> 107\u001b[0m         epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    109\u001b[0m         epoch_acc \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m acc\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m epoch_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader), epoch_acc \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in tqdm.tqdm(range(300)):\n",
    "\n",
    "\n",
    "    print(f\"epochs:{i+1}\")\n",
    "    \n",
    "    #training\n",
    "    tr_loss,tr_acc=training(dataloader, model, criterion,optimizer)\n",
    "    print(f'training_loss:{tr_loss}, acc:{tr_acc}')\n",
    "\n",
    "    #evaluating\n",
    "    ts_loss,ts_acc=evaluate(testloader, model,  criterion,optimizer)\n",
    "    print(f'ts_loss:{ts_loss}, ts_acc:{ts_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7b4644c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>prompt</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "      <td>The review is [MASK]. Review: I thought this m...</td>\n",
       "      <td>3893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "      <td>The review is [MASK]. Review: No one expects t...</td>\n",
       "      <td>4997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment  \\\n",
       "49995  I thought this movie did a down right good job...  positive   \n",
       "49999  No one expects the Star Trek movies to be high...  negative   \n",
       "\n",
       "                                                  prompt  target  \n",
       "49995  The review is [MASK]. Review: I thought this m...    3893  \n",
       "49999  The review is [MASK]. Review: No one expects t...    4997  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3006df66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(batch):\n",
    "    dic=tokenizer(batch[\"review\"], add_special_tokens=True, truncation=True, padding=True, return_tensors='pt',  max_length=512)\n",
    "    dic[\"label\"]=batch[\"target_2\"]\n",
    "    return dic\n",
    "\n",
    "\n",
    "dataset = Dataset.from_pandas(one_shot)\n",
    "dataset.set_transform(encode)\n",
    "# In[ ]:\n",
    "testset = Dataset.from_pandas(data[:5000])\n",
    "testset.set_transform(encode)\n",
    "\n",
    "def pad_TextSequence(batch):\n",
    "      return torch.nn.utils.rnn.pad_sequence(batch,batch_first=True, padding_value=0)\n",
    "\n",
    "def collate_fn(batch):\n",
    "  # A data tuple has the form:\n",
    "  # waveform,  label\n",
    "    texts, codes = [], []\n",
    "  # Gather in lists, and encode labels as indices\n",
    "    #print(batch)\n",
    "    for i in batch:\n",
    "        texts += [i['input_ids']]\n",
    "        codes += [i['label']]\n",
    "  # Group the list of tensors into a batched tensor\n",
    "    #tensors = pad_AudioSequence(tensors)\n",
    "    targets = pad_TextSequence(texts)\n",
    "    codes=torch.tensor(codes)\n",
    "    return  targets,codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5819fde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=2,collate_fn=collate_fn,shuffle=True)\n",
    "testloader = DataLoader(testset, batch_size=2,collate_fn=collate_fn,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7053ffc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
